Args in experiment:
Namespace(batch_size=128, c_out=137, checkpoints='./checkpoints', d_model=512, data='Solar', data_path='solar_AL.txt', dec_in=137, des='Exp', devices='0,1,2,3', dropout=0.2, enc_in=137, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0005, loss='mse', lradj='constant', model='Leddam', model_id='solar_96_720', n_layers=3, num_workers=0, patience=6, pe_type='no', pred_len=720, revin=True, root_path='dataset/Solar/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : solar_AL_pl720_n_layers_3_d_model_512_dropout_0.2_pe_type_no_bs_128_lr_0.0005>>>>>>>>>>>>>>>>>>>>>>>>>>
train 35977
val 4537
test 9793
Epoch: 1 cost time: 112.12843632698059
Epoch: 1, Steps: 281 | Train Loss: 0.286  vali_loss: 0.201   test_loss: 0.285 
Validation loss decreased (inf --> 0.201438).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 110.67702579498291
Epoch: 2, Steps: 281 | Train Loss: 0.235  vali_loss: 0.191   test_loss: 0.278 
Validation loss decreased (0.201438 --> 0.190879).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 111.27402257919312
Epoch: 3, Steps: 281 | Train Loss: 0.224  vali_loss: 0.189   test_loss: 0.264 
Validation loss decreased (0.190879 --> 0.188857).  Saving model ...
Updating learning rate to 0.0005
Epoch: 4 cost time: 111.12131261825562
Epoch: 4, Steps: 281 | Train Loss: 0.219  vali_loss: 0.188   test_loss: 0.266 
Validation loss decreased (0.188857 --> 0.188345).  Saving model ...
Updating learning rate to 0.0005
Epoch: 5 cost time: 110.8594217300415
Epoch: 5, Steps: 281 | Train Loss: 0.215  vali_loss: 0.189   test_loss: 0.253 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 6 cost time: 110.73784279823303
Epoch: 6, Steps: 281 | Train Loss: 0.213  vali_loss: 0.184   test_loss: 0.250 
Validation loss decreased (0.188345 --> 0.183916).  Saving model ...
Updating learning rate to 0.0005
Epoch: 7 cost time: 110.43546295166016
Epoch: 7, Steps: 281 | Train Loss: 0.210  vali_loss: 0.185   test_loss: 0.247 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 8 cost time: 112.15132594108582
Epoch: 8, Steps: 281 | Train Loss: 0.208  vali_loss: 0.188   test_loss: 0.246 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 9 cost time: 112.7006504535675
Epoch: 9, Steps: 281 | Train Loss: 0.206  vali_loss: 0.187   test_loss: 0.255 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 10 cost time: 113.956458568573
Epoch: 10, Steps: 281 | Train Loss: 0.204  vali_loss: 0.186   test_loss: 0.246 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 11 cost time: 113.84999752044678
Epoch: 11, Steps: 281 | Train Loss: 0.202  vali_loss: 0.188   test_loss: 0.251 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0005
Epoch: 12 cost time: 113.05169987678528
Epoch: 12, Steps: 281 | Train Loss: 0.200  vali_loss: 0.184   test_loss: 0.247 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : solar_AL_pl720_n_layers_3_d_model_512_dropout_0.2_pe_type_no_bs_128_lr_0.0005<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9793
loading model
Model weights deleted.
test shape: (9793, 720, 137) (9793, 720, 137)
mse:  0.250  mae:  0.281
