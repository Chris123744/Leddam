Args in experiment:
Namespace(batch_size=128, c_out=137, checkpoints='./checkpoints', d_model=512, data='Solar', data_path='solar_AL.txt', dec_in=137, des='Exp', devices='0,1,2,3', dropout=0.5, enc_in=137, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0005, loss='mse', lradj='constant', model='Leddam', model_id='solar_96_336', n_layers=3, num_workers=0, patience=6, pe_type='no', pred_len=336, revin=True, root_path='dataset/Solar/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : solar_AL_pl336_n_layers_3_d_model_512_dropout_0.5_pe_type_no_bs_128_lr_0.0005>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36361
val 4921
test 10177
Epoch: 1 cost time: 109.5986852645874
Epoch: 1, Steps: 284 | Train Loss: 0.291  vali_loss: 0.208   test_loss: 0.300 
Validation loss decreased (inf --> 0.207559).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 103.2627899646759
Epoch: 2, Steps: 284 | Train Loss: 0.241  vali_loss: 0.194   test_loss: 0.270 
Validation loss decreased (0.207559 --> 0.193758).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 103.5787947177887
Epoch: 3, Steps: 284 | Train Loss: 0.229  vali_loss: 0.187   test_loss: 0.274 
Validation loss decreased (0.193758 --> 0.187339).  Saving model ...
Updating learning rate to 0.0005
Epoch: 4 cost time: 104.14413738250732
Epoch: 4, Steps: 284 | Train Loss: 0.224  vali_loss: 0.191   test_loss: 0.264 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 5 cost time: 103.80666375160217
Epoch: 5, Steps: 284 | Train Loss: 0.219  vali_loss: 0.188   test_loss: 0.262 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 6 cost time: 104.21836256980896
Epoch: 6, Steps: 284 | Train Loss: 0.216  vali_loss: 0.191   test_loss: 0.260 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 7 cost time: 102.44397926330566
Epoch: 7, Steps: 284 | Train Loss: 0.214  vali_loss: 0.188   test_loss: 0.257 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 8 cost time: 102.31962060928345
Epoch: 8, Steps: 284 | Train Loss: 0.213  vali_loss: 0.187   test_loss: 0.248 
Validation loss decreased (0.187339 --> 0.187105).  Saving model ...
Updating learning rate to 0.0005
Epoch: 9 cost time: 99.96989965438843
Epoch: 9, Steps: 284 | Train Loss: 0.211  vali_loss: 0.187   test_loss: 0.249 
Validation loss decreased (0.187105 --> 0.186693).  Saving model ...
Updating learning rate to 0.0005
Epoch: 10 cost time: 100.35196685791016
Epoch: 10, Steps: 284 | Train Loss: 0.209  vali_loss: 0.188   test_loss: 0.250 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 11 cost time: 99.30640006065369
Epoch: 11, Steps: 284 | Train Loss: 0.209  vali_loss: 0.188   test_loss: 0.252 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 12 cost time: 99.49412512779236
Epoch: 12, Steps: 284 | Train Loss: 0.208  vali_loss: 0.187   test_loss: 0.246 
Validation loss decreased (0.186693 --> 0.186588).  Saving model ...
Updating learning rate to 0.0005
Epoch: 13 cost time: 99.59556746482849
Epoch: 13, Steps: 284 | Train Loss: 0.206  vali_loss: 0.185   test_loss: 0.245 
Validation loss decreased (0.186588 --> 0.185208).  Saving model ...
Updating learning rate to 0.0005
Epoch: 14 cost time: 99.0146586894989
Epoch: 14, Steps: 284 | Train Loss: 0.205  vali_loss: 0.183   test_loss: 0.240 
Validation loss decreased (0.185208 --> 0.182502).  Saving model ...
Updating learning rate to 0.0005
Epoch: 15 cost time: 99.02187037467957
Epoch: 15, Steps: 284 | Train Loss: 0.204  vali_loss: 0.191   test_loss: 0.249 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 16 cost time: 99.1781063079834
Epoch: 16, Steps: 284 | Train Loss: 0.202  vali_loss: 0.185   test_loss: 0.247 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 17 cost time: 99.92406034469604
Epoch: 17, Steps: 284 | Train Loss: 0.202  vali_loss: 0.189   test_loss: 0.250 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 18 cost time: 99.66100692749023
Epoch: 18, Steps: 284 | Train Loss: 0.201  vali_loss: 0.182   test_loss: 0.249 
Validation loss decreased (0.182502 --> 0.181619).  Saving model ...
Updating learning rate to 0.0005
Epoch: 19 cost time: 99.94841122627258
Epoch: 19, Steps: 284 | Train Loss: 0.200  vali_loss: 0.181   test_loss: 0.248 
Validation loss decreased (0.181619 --> 0.180942).  Saving model ...
Updating learning rate to 0.0005
Epoch: 20 cost time: 99.8201265335083
Epoch: 20, Steps: 284 | Train Loss: 0.199  vali_loss: 0.189   test_loss: 0.245 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 21 cost time: 99.69407415390015
Epoch: 21, Steps: 284 | Train Loss: 0.198  vali_loss: 0.184   test_loss: 0.244 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 22 cost time: 99.93089962005615
Epoch: 22, Steps: 284 | Train Loss: 0.197  vali_loss: 0.181   test_loss: 0.241 
Validation loss decreased (0.180942 --> 0.180897).  Saving model ...
Updating learning rate to 0.0005
Epoch: 23 cost time: 100.30274510383606
Epoch: 23, Steps: 284 | Train Loss: 0.196  vali_loss: 0.184   test_loss: 0.241 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 24 cost time: 98.79325032234192
Epoch: 24, Steps: 284 | Train Loss: 0.195  vali_loss: 0.185   test_loss: 0.242 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 25 cost time: 99.16433238983154
Epoch: 25, Steps: 284 | Train Loss: 0.194  vali_loss: 0.189   test_loss: 0.245 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 26 cost time: 98.76335978507996
Epoch: 26, Steps: 284 | Train Loss: 0.193  vali_loss: 0.185   test_loss: 0.238 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 27 cost time: 99.07560968399048
Epoch: 27, Steps: 284 | Train Loss: 0.192  vali_loss: 0.183   test_loss: 0.240 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0005
Epoch: 28 cost time: 98.83709359169006
Epoch: 28, Steps: 284 | Train Loss: 0.192  vali_loss: 0.183   test_loss: 0.238 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : solar_AL_pl336_n_layers_3_d_model_512_dropout_0.5_pe_type_no_bs_128_lr_0.0005<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10177
loading model
Model weights deleted.
test shape: (10177, 336, 137) (10177, 336, 137)
mse:  0.241  mae:  0.268
