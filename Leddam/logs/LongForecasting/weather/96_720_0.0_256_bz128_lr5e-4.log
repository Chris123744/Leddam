Args in experiment:
Namespace(batch_size=128, c_out=21, checkpoints='./checkpoints', d_model=256, data='custom', data_path='weather.csv', dec_in=21, des='Exp', devices='0,1,2,3', dropout=0.0, enc_in=21, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0005, loss='mse', lradj='constant', model='Leddam', model_id='weather_96_720', n_layers=1, num_workers=0, patience=6, pe_type='sincos', pred_len=720, revin=True, root_path='dataset/weather/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : weather_pl720_n_layers_1_d_model_256_dropout_0.0_pe_type_sincos_bs_128_lr_0.0005>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36072
val 4551
test 9820
Epoch: 1 cost time: 17.91343593597412
Epoch: 1, Steps: 281 | Train Loss: 0.683  vali_loss: 0.700   test_loss: 0.350 
Validation loss decreased (inf --> 0.699850).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 16.02441167831421
Epoch: 2, Steps: 281 | Train Loss: 0.651  vali_loss: 0.687   test_loss: 0.346 
Validation loss decreased (0.699850 --> 0.687029).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 14.763885259628296
Epoch: 3, Steps: 281 | Train Loss: 0.642  vali_loss: 0.680   test_loss: 0.345 
Validation loss decreased (0.687029 --> 0.680416).  Saving model ...
Updating learning rate to 0.0005
Epoch: 4 cost time: 16.537968635559082
Epoch: 4, Steps: 281 | Train Loss: 0.634  vali_loss: 0.679   test_loss: 0.345 
Validation loss decreased (0.680416 --> 0.678730).  Saving model ...
Updating learning rate to 0.0005
Epoch: 5 cost time: 16.475631713867188
Epoch: 5, Steps: 281 | Train Loss: 0.627  vali_loss: 0.676   test_loss: 0.344 
Validation loss decreased (0.678730 --> 0.675944).  Saving model ...
Updating learning rate to 0.0005
Epoch: 6 cost time: 16.721540212631226
Epoch: 6, Steps: 281 | Train Loss: 0.619  vali_loss: 0.667   test_loss: 0.343 
Validation loss decreased (0.675944 --> 0.667002).  Saving model ...
Updating learning rate to 0.0005
Epoch: 7 cost time: 16.796926736831665
Epoch: 7, Steps: 281 | Train Loss: 0.612  vali_loss: 0.674   test_loss: 0.346 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 8 cost time: 14.766449213027954
Epoch: 8, Steps: 281 | Train Loss: 0.607  vali_loss: 0.668   test_loss: 0.344 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 9 cost time: 16.37244176864624
Epoch: 9, Steps: 281 | Train Loss: 0.601  vali_loss: 0.671   test_loss: 0.344 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 10 cost time: 16.94912314414978
Epoch: 10, Steps: 281 | Train Loss: 0.596  vali_loss: 0.675   test_loss: 0.345 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 11 cost time: 16.48057770729065
Epoch: 11, Steps: 281 | Train Loss: 0.590  vali_loss: 0.670   test_loss: 0.346 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0005
Epoch: 12 cost time: 16.04526162147522
Epoch: 12, Steps: 281 | Train Loss: 0.583  vali_loss: 0.675   test_loss: 0.347 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : weather_pl720_n_layers_1_d_model_256_dropout_0.0_pe_type_sincos_bs_128_lr_0.0005<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
loading model
Model weights deleted.
test shape: (9820, 720, 21) (9820, 720, 21)
mse:  0.343  mae:  0.343
