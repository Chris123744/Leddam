Args in experiment:
Namespace(batch_size=128, c_out=21, checkpoints='./checkpoints', d_model=256, data='custom', data_path='weather.csv', dec_in=21, des='Exp', devices='0,1,2,3', dropout=0.5, enc_in=21, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0005, loss='mse', lradj='constant', model='Leddam', model_id='weather_96_192', n_layers=1, num_workers=0, patience=6, pe_type='sincos', pred_len=192, revin=True, root_path='dataset/weather/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : weather_pl192_n_layers_1_d_model_256_dropout_0.5_pe_type_sincos_bs_128_lr_0.0005>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36600
val 5079
test 10348
Epoch: 1 cost time: 13.750259160995483
Epoch: 1, Steps: 285 | Train Loss: 0.539  vali_loss: 0.494   test_loss: 0.221 
Validation loss decreased (inf --> 0.493531).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 12.426581859588623
Epoch: 2, Steps: 285 | Train Loss: 0.502  vali_loss: 0.474   test_loss: 0.215 
Validation loss decreased (0.493531 --> 0.473833).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 13.097454071044922
Epoch: 3, Steps: 285 | Train Loss: 0.491  vali_loss: 0.470   test_loss: 0.212 
Validation loss decreased (0.473833 --> 0.469825).  Saving model ...
Updating learning rate to 0.0005
Epoch: 4 cost time: 12.583670616149902
Epoch: 4, Steps: 285 | Train Loss: 0.486  vali_loss: 0.465   test_loss: 0.212 
Validation loss decreased (0.469825 --> 0.465400).  Saving model ...
Updating learning rate to 0.0005
Epoch: 5 cost time: 12.599982738494873
Epoch: 5, Steps: 285 | Train Loss: 0.483  vali_loss: 0.461   test_loss: 0.209 
Validation loss decreased (0.465400 --> 0.460877).  Saving model ...
Updating learning rate to 0.0005
Epoch: 6 cost time: 12.684417486190796
Epoch: 6, Steps: 285 | Train Loss: 0.478  vali_loss: 0.461   test_loss: 0.209 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 7 cost time: 12.389341115951538
Epoch: 7, Steps: 285 | Train Loss: 0.475  vali_loss: 0.463   test_loss: 0.208 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 8 cost time: 11.90952181816101
Epoch: 8, Steps: 285 | Train Loss: 0.472  vali_loss: 0.459   test_loss: 0.209 
Validation loss decreased (0.460877 --> 0.458993).  Saving model ...
Updating learning rate to 0.0005
Epoch: 9 cost time: 12.185950517654419
Epoch: 9, Steps: 285 | Train Loss: 0.469  vali_loss: 0.461   test_loss: 0.208 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 10 cost time: 13.693715572357178
Epoch: 10, Steps: 285 | Train Loss: 0.469  vali_loss: 0.460   test_loss: 0.207 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 11 cost time: 12.922600984573364
Epoch: 11, Steps: 285 | Train Loss: 0.465  vali_loss: 0.456   test_loss: 0.206 
Validation loss decreased (0.458993 --> 0.455988).  Saving model ...
Updating learning rate to 0.0005
Epoch: 12 cost time: 12.766699075698853
Epoch: 12, Steps: 285 | Train Loss: 0.465  vali_loss: 0.458   test_loss: 0.208 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 13 cost time: 12.444786071777344
Epoch: 13, Steps: 285 | Train Loss: 0.463  vali_loss: 0.457   test_loss: 0.207 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 14 cost time: 13.309633255004883
Epoch: 14, Steps: 285 | Train Loss: 0.461  vali_loss: 0.457   test_loss: 0.207 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 15 cost time: 12.222073316574097
Epoch: 15, Steps: 285 | Train Loss: 0.460  vali_loss: 0.456   test_loss: 0.205 
Validation loss decreased (0.455988 --> 0.455507).  Saving model ...
Updating learning rate to 0.0005
Epoch: 16 cost time: 11.012542009353638
Epoch: 16, Steps: 285 | Train Loss: 0.460  vali_loss: 0.458   test_loss: 0.207 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 17 cost time: 11.91560959815979
Epoch: 17, Steps: 285 | Train Loss: 0.461  vali_loss: 0.452   test_loss: 0.207 
Validation loss decreased (0.455507 --> 0.451515).  Saving model ...
Updating learning rate to 0.0005
Epoch: 18 cost time: 12.840559482574463
Epoch: 18, Steps: 285 | Train Loss: 0.457  vali_loss: 0.456   test_loss: 0.206 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 19 cost time: 12.252668380737305
Epoch: 19, Steps: 285 | Train Loss: 0.456  vali_loss: 0.458   test_loss: 0.206 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 20 cost time: 12.396252632141113
Epoch: 20, Steps: 285 | Train Loss: 0.455  vali_loss: 0.455   test_loss: 0.205 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 21 cost time: 12.971956014633179
Epoch: 21, Steps: 285 | Train Loss: 0.453  vali_loss: 0.457   test_loss: 0.206 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 22 cost time: 11.663216829299927
Epoch: 22, Steps: 285 | Train Loss: 0.453  vali_loss: 0.457   test_loss: 0.206 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0005
Epoch: 23 cost time: 12.208504676818848
Epoch: 23, Steps: 285 | Train Loss: 0.452  vali_loss: 0.456   test_loss: 0.207 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : weather_pl192_n_layers_1_d_model_256_dropout_0.5_pe_type_sincos_bs_128_lr_0.0005<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
loading model
Model weights deleted.
test shape: (10348, 192, 21) (10348, 192, 21)
mse:  0.207  mae:  0.250
