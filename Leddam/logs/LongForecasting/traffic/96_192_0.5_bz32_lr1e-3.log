Args in experiment:
Namespace(batch_size=32, c_out=862, checkpoints='./checkpoints', d_model=256, data='custom', data_path='traffic.csv', dec_in=862, des='Exp', devices='0,1,2,3', dropout=0.5, enc_in=862, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.001, loss='mse', lradj='constant', model='Leddam', model_id='traffic_96_192', n_layers=3, num_workers=0, patience=6, pe_type='no', pred_len=192, revin=True, root_path='dataset/traffic/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : traffic_pl192_n_layers_3_d_model_256_dropout_0.5_pe_type_no_bs_32_lr_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11993
val 1565
test 3317
Epoch: 1 cost time: 281.1694574356079
Epoch: 1, Steps: 374 | Train Loss: 0.326  vali_loss: 0.407   test_loss: 0.482 
Validation loss decreased (inf --> 0.406951).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 240.83366322517395
Epoch: 2, Steps: 374 | Train Loss: 0.278  vali_loss: 0.391   test_loss: 0.465 
Validation loss decreased (0.406951 --> 0.391228).  Saving model ...
Updating learning rate to 0.001
Epoch: 3 cost time: 224.5559437274933
Epoch: 3, Steps: 374 | Train Loss: 0.267  vali_loss: 0.384   test_loss: 0.458 
Validation loss decreased (0.391228 --> 0.383991).  Saving model ...
Updating learning rate to 0.001
Epoch: 4 cost time: 225.41542267799377
Epoch: 4, Steps: 374 | Train Loss: 0.261  vali_loss: 0.384   test_loss: 0.460 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 5 cost time: 221.83855986595154
Epoch: 5, Steps: 374 | Train Loss: 0.256  vali_loss: 0.385   test_loss: 0.461 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 6 cost time: 204.3578541278839
Epoch: 6, Steps: 374 | Train Loss: 0.254  vali_loss: 0.379   test_loss: 0.454 
Validation loss decreased (0.383991 --> 0.378782).  Saving model ...
Updating learning rate to 0.001
Epoch: 7 cost time: 202.84342193603516
Epoch: 7, Steps: 374 | Train Loss: 0.252  vali_loss: 0.377   test_loss: 0.456 
Validation loss decreased (0.378782 --> 0.377239).  Saving model ...
Updating learning rate to 0.001
Epoch: 8 cost time: 204.0342197418213
Epoch: 8, Steps: 374 | Train Loss: 0.251  vali_loss: 0.378   test_loss: 0.453 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 9 cost time: 206.6874897480011
Epoch: 9, Steps: 374 | Train Loss: 0.249  vali_loss: 0.378   test_loss: 0.457 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 10 cost time: 196.6307077407837
Epoch: 10, Steps: 374 | Train Loss: 0.249  vali_loss: 0.375   test_loss: 0.455 
Validation loss decreased (0.377239 --> 0.375316).  Saving model ...
Updating learning rate to 0.001
Epoch: 11 cost time: 185.98880910873413
Epoch: 11, Steps: 374 | Train Loss: 0.248  vali_loss: 0.374   test_loss: 0.458 
Validation loss decreased (0.375316 --> 0.373923).  Saving model ...
Updating learning rate to 0.001
Epoch: 12 cost time: 178.40437817573547
Epoch: 12, Steps: 374 | Train Loss: 0.247  vali_loss: 0.376   test_loss: 0.457 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 13 cost time: 182.18740010261536
Epoch: 13, Steps: 374 | Train Loss: 0.246  vali_loss: 0.375   test_loss: 0.454 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 14 cost time: 180.4460940361023
Epoch: 14, Steps: 374 | Train Loss: 0.245  vali_loss: 0.380   test_loss: 0.464 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.001
Epoch: 15 cost time: 180.5490221977234
Epoch: 15, Steps: 374 | Train Loss: 0.245  vali_loss: 0.375   test_loss: 0.456 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.001
Epoch: 16 cost time: 179.4782257080078
Epoch: 16, Steps: 374 | Train Loss: 0.245  vali_loss: 0.389   test_loss: 0.473 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.001
Epoch: 17 cost time: 183.49989485740662
Epoch: 17, Steps: 374 | Train Loss: 0.246  vali_loss: 0.375   test_loss: 0.458 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : traffic_pl192_n_layers_3_d_model_256_dropout_0.5_pe_type_no_bs_32_lr_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3317
loading model
Model weights deleted.
test shape: (3317, 192, 862) (3317, 192, 862)
mse:  0.458  mae:  0.289
