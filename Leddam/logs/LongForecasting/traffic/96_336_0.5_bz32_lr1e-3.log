Args in experiment:
Namespace(batch_size=32, c_out=862, checkpoints='./checkpoints', d_model=256, data='custom', data_path='traffic.csv', dec_in=862, des='Exp', devices='0,1,2,3', dropout=0.5, enc_in=862, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.001, loss='mse', lradj='constant', model='Leddam', model_id='traffic_96_336', n_layers=3, num_workers=0, patience=6, pe_type='no', pred_len=336, revin=True, root_path='dataset/traffic/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : traffic_pl336_n_layers_3_d_model_256_dropout_0.5_pe_type_no_bs_32_lr_0.001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11849
val 1421
test 3173
Epoch: 1 cost time: 199.54853534698486
Epoch: 1, Steps: 370 | Train Loss: 0.334  vali_loss: 0.421   test_loss: 0.498 
Validation loss decreased (inf --> 0.420504).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 196.56751322746277
Epoch: 2, Steps: 370 | Train Loss: 0.287  vali_loss: 0.404   test_loss: 0.482 
Validation loss decreased (0.420504 --> 0.403907).  Saving model ...
Updating learning rate to 0.001
Epoch: 3 cost time: 194.25175261497498
Epoch: 3, Steps: 370 | Train Loss: 0.277  vali_loss: 0.396   test_loss: 0.474 
Validation loss decreased (0.403907 --> 0.396051).  Saving model ...
Updating learning rate to 0.001
Epoch: 4 cost time: 197.95500421524048
Epoch: 4, Steps: 370 | Train Loss: 0.271  vali_loss: 0.396   test_loss: 0.471 
Validation loss decreased (0.396051 --> 0.395587).  Saving model ...
Updating learning rate to 0.001
Epoch: 5 cost time: 200.9431915283203
Epoch: 5, Steps: 370 | Train Loss: 0.268  vali_loss: 0.394   test_loss: 0.480 
Validation loss decreased (0.395587 --> 0.394441).  Saving model ...
Updating learning rate to 0.001
Epoch: 6 cost time: 202.64223647117615
Epoch: 6, Steps: 370 | Train Loss: 0.264  vali_loss: 0.391   test_loss: 0.482 
Validation loss decreased (0.394441 --> 0.390987).  Saving model ...
Updating learning rate to 0.001
Epoch: 7 cost time: 202.46206545829773
Epoch: 7, Steps: 370 | Train Loss: 0.262  vali_loss: 0.389   test_loss: 0.482 
Validation loss decreased (0.390987 --> 0.388508).  Saving model ...
Updating learning rate to 0.001
Epoch: 8 cost time: 203.82260918617249
Epoch: 8, Steps: 370 | Train Loss: 0.260  vali_loss: 0.391   test_loss: 0.484 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 9 cost time: 200.14825415611267
Epoch: 9, Steps: 370 | Train Loss: 0.259  vali_loss: 0.390   test_loss: 0.496 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 10 cost time: 207.160302400589
Epoch: 10, Steps: 370 | Train Loss: 0.258  vali_loss: 0.388   test_loss: 0.487 
Validation loss decreased (0.388508 --> 0.388358).  Saving model ...
Updating learning rate to 0.001
Epoch: 11 cost time: 202.81681632995605
Epoch: 11, Steps: 370 | Train Loss: 0.257  vali_loss: 0.389   test_loss: 0.488 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 12 cost time: 203.59498977661133
Epoch: 12, Steps: 370 | Train Loss: 0.257  vali_loss: 0.390   test_loss: 0.493 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 13 cost time: 198.2318413257599
Epoch: 13, Steps: 370 | Train Loss: 0.255  vali_loss: 0.393   test_loss: 0.487 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.001
Epoch: 14 cost time: 200.0022611618042
Epoch: 14, Steps: 370 | Train Loss: 0.254  vali_loss: 0.387   test_loss: 0.486 
Validation loss decreased (0.388358 --> 0.387451).  Saving model ...
Updating learning rate to 0.001
Epoch: 15 cost time: 207.13561534881592
Epoch: 15, Steps: 370 | Train Loss: 0.253  vali_loss: 0.392   test_loss: 0.505 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.001
Epoch: 16 cost time: 194.17024159431458
Epoch: 16, Steps: 370 | Train Loss: 0.253  vali_loss: 0.389   test_loss: 0.490 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.001
Epoch: 17 cost time: 186.8825969696045
Epoch: 17, Steps: 370 | Train Loss: 0.252  vali_loss: 0.389   test_loss: 0.486 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.001
Epoch: 18 cost time: 188.96116757392883
Epoch: 18, Steps: 370 | Train Loss: 0.252  vali_loss: 0.391   test_loss: 0.490 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.001
Epoch: 19 cost time: 187.27701568603516
Epoch: 19, Steps: 370 | Train Loss: 0.252  vali_loss: 0.388   test_loss: 0.485 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.001
Epoch: 20 cost time: 186.64168572425842
Epoch: 20, Steps: 370 | Train Loss: 0.251  vali_loss: 0.391   test_loss: 0.495 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : traffic_pl336_n_layers_3_d_model_256_dropout_0.5_pe_type_no_bs_32_lr_0.001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3173
loading model
Model weights deleted.
test shape: (3173, 336, 862) (3173, 336, 862)
mse:  0.486  mae:  0.297
