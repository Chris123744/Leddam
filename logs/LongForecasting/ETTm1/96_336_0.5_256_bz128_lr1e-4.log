Args in experiment:
Namespace(batch_size=128, c_out=7, checkpoints='./checkpoints', d_model=256, data='ETTm1', data_path='ETTm1.csv', dec_in=7, des='Exp', devices='0,1,2,3', dropout=0.5, enc_in=7, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='constant', model='Leddam', model_id='ETTm1_96_336', n_layers=1, num_workers=0, patience=6, pe_type='sincos', pred_len=336, revin=True, root_path='dataset/ETT-small/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTm1_pl336_n_layers_1_d_model_256_dropout_0.5_pe_type_sincos_bs_128_lr_0.0001>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
Epoch: 1 cost time: 8.830647945404053
Epoch: 1, Steps: 266 | Train Loss: 0.416  vali_loss: 0.665   test_loss: 0.405 
Validation loss decreased (inf --> 0.665375).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 7.1993567943573
Epoch: 2, Steps: 266 | Train Loss: 0.389  vali_loss: 0.659   test_loss: 0.403 
Validation loss decreased (0.665375 --> 0.658679).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 7.405013084411621
Epoch: 3, Steps: 266 | Train Loss: 0.382  vali_loss: 0.657   test_loss: 0.402 
Validation loss decreased (0.658679 --> 0.656926).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 7.4274585247039795
Epoch: 4, Steps: 266 | Train Loss: 0.377  vali_loss: 0.655   test_loss: 0.399 
Validation loss decreased (0.656926 --> 0.654957).  Saving model ...
Updating learning rate to 0.0001
Epoch: 5 cost time: 7.563991546630859
Epoch: 5, Steps: 266 | Train Loss: 0.374  vali_loss: 0.655   test_loss: 0.401 
Validation loss decreased (0.654957 --> 0.654527).  Saving model ...
Updating learning rate to 0.0001
Epoch: 6 cost time: 7.597317218780518
Epoch: 6, Steps: 266 | Train Loss: 0.372  vali_loss: 0.655   test_loss: 0.399 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 7 cost time: 7.410839080810547
Epoch: 7, Steps: 266 | Train Loss: 0.370  vali_loss: 0.651   test_loss: 0.397 
Validation loss decreased (0.654527 --> 0.650811).  Saving model ...
Updating learning rate to 0.0001
Epoch: 8 cost time: 7.281630277633667
Epoch: 8, Steps: 266 | Train Loss: 0.368  vali_loss: 0.650   test_loss: 0.396 
Validation loss decreased (0.650811 --> 0.649795).  Saving model ...
Updating learning rate to 0.0001
Epoch: 9 cost time: 7.2944865226745605
Epoch: 9, Steps: 266 | Train Loss: 0.366  vali_loss: 0.651   test_loss: 0.394 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 10 cost time: 7.357051372528076
Epoch: 10, Steps: 266 | Train Loss: 0.364  vali_loss: 0.646   test_loss: 0.393 
Validation loss decreased (0.649795 --> 0.645876).  Saving model ...
Updating learning rate to 0.0001
Epoch: 11 cost time: 7.09719181060791
Epoch: 11, Steps: 266 | Train Loss: 0.362  vali_loss: 0.643   test_loss: 0.395 
Validation loss decreased (0.645876 --> 0.642873).  Saving model ...
Updating learning rate to 0.0001
Epoch: 12 cost time: 7.114270210266113
Epoch: 12, Steps: 266 | Train Loss: 0.360  vali_loss: 0.642   test_loss: 0.394 
Validation loss decreased (0.642873 --> 0.642400).  Saving model ...
Updating learning rate to 0.0001
Epoch: 13 cost time: 7.094117641448975
Epoch: 13, Steps: 266 | Train Loss: 0.359  vali_loss: 0.641   test_loss: 0.395 
Validation loss decreased (0.642400 --> 0.640685).  Saving model ...
Updating learning rate to 0.0001
Epoch: 14 cost time: 7.041211366653442
Epoch: 14, Steps: 266 | Train Loss: 0.357  vali_loss: 0.644   test_loss: 0.394 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 15 cost time: 7.237424850463867
Epoch: 15, Steps: 266 | Train Loss: 0.356  vali_loss: 0.639   test_loss: 0.395 
Validation loss decreased (0.640685 --> 0.638510).  Saving model ...
Updating learning rate to 0.0001
Epoch: 16 cost time: 7.229321718215942
Epoch: 16, Steps: 266 | Train Loss: 0.355  vali_loss: 0.641   test_loss: 0.394 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 17 cost time: 7.180250406265259
Epoch: 17, Steps: 266 | Train Loss: 0.354  vali_loss: 0.641   test_loss: 0.395 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0001
Epoch: 18 cost time: 7.132047891616821
Epoch: 18, Steps: 266 | Train Loss: 0.353  vali_loss: 0.640   test_loss: 0.393 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0001
Epoch: 19 cost time: 7.100716829299927
Epoch: 19, Steps: 266 | Train Loss: 0.351  vali_loss: 0.639   test_loss: 0.392 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0001
Epoch: 20 cost time: 7.1075358390808105
Epoch: 20, Steps: 266 | Train Loss: 0.351  vali_loss: 0.637   test_loss: 0.394 
Validation loss decreased (0.638510 --> 0.637148).  Saving model ...
Updating learning rate to 0.0001
Epoch: 21 cost time: 7.117637634277344
Epoch: 21, Steps: 266 | Train Loss: 0.349  vali_loss: 0.638   test_loss: 0.400 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 22 cost time: 6.874493837356567
Epoch: 22, Steps: 266 | Train Loss: 0.348  vali_loss: 0.639   test_loss: 0.394 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0001
Epoch: 23 cost time: 6.94635534286499
Epoch: 23, Steps: 266 | Train Loss: 0.348  vali_loss: 0.637   test_loss: 0.394 
Validation loss decreased (0.637148 --> 0.636751).  Saving model ...
Updating learning rate to 0.0001
Epoch: 24 cost time: 7.14720892906189
Epoch: 24, Steps: 266 | Train Loss: 0.347  vali_loss: 0.639   test_loss: 0.395 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0001
Epoch: 25 cost time: 7.1111159324646
Epoch: 25, Steps: 266 | Train Loss: 0.346  vali_loss: 0.639   test_loss: 0.395 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0001
Epoch: 26 cost time: 6.939266920089722
Epoch: 26, Steps: 266 | Train Loss: 0.346  vali_loss: 0.642   test_loss: 0.394 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0001
Epoch: 27 cost time: 7.037255048751831
Epoch: 27, Steps: 266 | Train Loss: 0.345  vali_loss: 0.639   test_loss: 0.395 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0001
Epoch: 28 cost time: 7.086058855056763
Epoch: 28, Steps: 266 | Train Loss: 0.344  vali_loss: 0.639   test_loss: 0.394 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0001
Epoch: 29 cost time: 7.097444534301758
Epoch: 29, Steps: 266 | Train Loss: 0.343  vali_loss: 0.640   test_loss: 0.393 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : ETTm1_pl336_n_layers_1_d_model_256_dropout_0.5_pe_type_sincos_bs_128_lr_0.0001<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
loading model
Model weights deleted.
test shape: (11185, 336, 7) (11185, 336, 7)
mse:  0.394  mae:  0.402
