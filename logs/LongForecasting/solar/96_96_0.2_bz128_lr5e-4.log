Args in experiment:
Namespace(batch_size=128, c_out=137, checkpoints='./checkpoints', d_model=512, data='Solar', data_path='solar_AL.txt', dec_in=137, des='Exp', devices='0,1,2,3', dropout=0.2, enc_in=137, features='M', freq='h', gpu=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0005, loss='mse', lradj='constant', model='Leddam', model_id='solar_96_96', n_layers=3, num_workers=0, patience=6, pe_type='no', pred_len=96, revin=True, root_path='dataset/Solar/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=100, use_amp=True, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : solar_AL_pl96_n_layers_3_d_model_512_dropout_0.2_pe_type_no_bs_128_lr_0.0005>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36601
val 5161
test 10417
Epoch: 1 cost time: 117.48282074928284
Epoch: 1, Steps: 285 | Train Loss: 0.247  vali_loss: 0.177   test_loss: 0.244 
Validation loss decreased (inf --> 0.177038).  Saving model ...
Updating learning rate to 0.0005
Epoch: 2 cost time: 107.81859683990479
Epoch: 2, Steps: 285 | Train Loss: 0.205  vali_loss: 0.172   test_loss: 0.233 
Validation loss decreased (0.177038 --> 0.172418).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 104.50493550300598
Epoch: 3, Steps: 285 | Train Loss: 0.195  vali_loss: 0.167   test_loss: 0.219 
Validation loss decreased (0.172418 --> 0.167418).  Saving model ...
Updating learning rate to 0.0005
Epoch: 4 cost time: 106.22191882133484
Epoch: 4, Steps: 285 | Train Loss: 0.193  vali_loss: 0.155   test_loss: 0.210 
Validation loss decreased (0.167418 --> 0.154687).  Saving model ...
Updating learning rate to 0.0005
Epoch: 5 cost time: 100.26080560684204
Epoch: 5, Steps: 285 | Train Loss: 0.189  vali_loss: 0.155   test_loss: 0.205 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 6 cost time: 101.08702659606934
Epoch: 6, Steps: 285 | Train Loss: 0.186  vali_loss: 0.158   test_loss: 0.208 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 7 cost time: 100.8703510761261
Epoch: 7, Steps: 285 | Train Loss: 0.188  vali_loss: 0.161   test_loss: 0.203 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 8 cost time: 99.6694564819336
Epoch: 8, Steps: 285 | Train Loss: 0.184  vali_loss: 0.158   test_loss: 0.205 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 9 cost time: 101.12428569793701
Epoch: 9, Steps: 285 | Train Loss: 0.185  vali_loss: 0.154   test_loss: 0.197 
Validation loss decreased (0.154687 --> 0.154348).  Saving model ...
Updating learning rate to 0.0005
Epoch: 10 cost time: 101.12951803207397
Epoch: 10, Steps: 285 | Train Loss: 0.183  vali_loss: 0.155   test_loss: 0.209 
EarlyStopping counter: 1 out of 6
Updating learning rate to 0.0005
Epoch: 11 cost time: 100.86927485466003
Epoch: 11, Steps: 285 | Train Loss: 0.185  vali_loss: 0.161   test_loss: 0.218 
EarlyStopping counter: 2 out of 6
Updating learning rate to 0.0005
Epoch: 12 cost time: 96.61033964157104
Epoch: 12, Steps: 285 | Train Loss: 0.185  vali_loss: 0.158   test_loss: 0.191 
EarlyStopping counter: 3 out of 6
Updating learning rate to 0.0005
Epoch: 13 cost time: 96.65378379821777
Epoch: 13, Steps: 285 | Train Loss: 0.180  vali_loss: 0.159   test_loss: 0.197 
EarlyStopping counter: 4 out of 6
Updating learning rate to 0.0005
Epoch: 14 cost time: 97.38845109939575
Epoch: 14, Steps: 285 | Train Loss: 0.196  vali_loss: 0.210   test_loss: 0.282 
EarlyStopping counter: 5 out of 6
Updating learning rate to 0.0005
Epoch: 15 cost time: 97.58359575271606
Epoch: 15, Steps: 285 | Train Loss: 0.203  vali_loss: 0.160   test_loss: 0.218 
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : solar_AL_pl96_n_layers_3_d_model_512_dropout_0.2_pe_type_no_bs_128_lr_0.0005<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10417
loading model
Model weights deleted.
test shape: (10417, 96, 137) (10417, 96, 137)
mse:  0.197  mae:  0.241
